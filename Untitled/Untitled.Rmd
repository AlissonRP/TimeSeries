---
title: "title"
author: "Alisson Rosa"
abstract: "abstract"
header-includes:
   - \usepackage[brazil]{babel}
   - \usepackage{bm}
   - \usepackage{float}
geometry: left=1.7cm, right=1.7cm, top=3cm, bottom=3cm
output:
  bookdown::pdf_document2:
    includes:
      before_body: beforebody.tex
editor_options:
  chunk_output_type: console
indent: true
toc: True
bibliography: bib.bib 
csl: style.csl
nocite: '@*'
link-citations: true
---




```{r setup,include=F}

options(digits = 3) # Arrendodamento
options(scipen = 999)
ggplot2::theme_set(ggplot2::theme_minimal())
knitr::opts_chunk$set(
  echo = F, message = F, warning = F, fig.pos = "H",
  fig.align = "center", fig.width = 6, fig.height = 3.5
)
scale_fill_discrete <- \(...) ggplot2::scale_fill_brewer(..., palette = "Set2")
```


\section{Introdução}
O Spotify é um serviço digital que dá acesso instantâneo a milhões de músicas, podcasts, vídeos e outros conteúdos de criadores no mundo todo. Pode ser acessado pelo *browser*, sendo possível também baixar o aplicativo, estando disponível para diversas plataformas digitais. 
Nesse ensaio, vamos analisar os *reviews* feitos na Play Store sobre a versão para *Android*, dessa maneira vamos examinar o comportamento da média dos reviews (estrelas) diária em uma perspectiva de série temporal, uma outra abordagem utilizando técnicas de NLP pode ser consultada clicando-se [aqui](https://github.com/AlissonRP/SpotifyReviews/blob/main/report.pdf).

```{r }
# R code
library(tidyverse)
library(forecast)
library(lubridate)
library(patchwork)




eqm = function(model, serie = y){
  resid = serie[2:length(serie)] - model$fitted[2:length(serie)]
  return(sum(resid^2) / (length(resid) - 1))
  
}

mape = function(model,  serie = y){
  resid = serie[2:length(serie)] - model$fitted[2:length(serie)]
  return((1/length(serie)) * sum(abs(resid)/abs(y[2:length(y)])))
}

source("analise_barmax/barma.r")
source("KARMA_BARMA/karma.r")

df = read_csv("../data/rates.csv")

df = df |>
  mutate(Time_submitted  = as.Date(Time_submitted, format = "%Y-%m-%d"))


df = df |> group_by(
  Time_submitted) |>
  summarise(rate = mean(Rating))

df = df |>  bind_cols(index = 1:nrow(df))
y = df$rate /  5
y <- ts(y, start = decimal_date(as.Date("2022-01-01")), frequency = 365)
```

You cross-reference tables like this: Table \@ref(tab:crftable)

\section{Metodologia}
Nessa seção são apresentados os modelos aqui utilizados, a saber: $\beta$ARMA, KARMA e ARIMA^[ARIMA: O modelo ARIMA já é bastante conhecido na literatura, portanto aqui é dispensado a sua introdução]

\subsection{Modelo $\beta$ARMA}
A distribuição beta é bastante conhecida pois consegue modelar variáveis aleatórias definidas em intervalos limitados, dessa maneira um caso particular importante é quando o intervalo é unitário iniciando em zero. Dessa maneira foi desenvolvido em @betarma o modelo com abordagem temporal para variáveis que podem ser modeladas pela distribuição beta.

Portanto, assumindo que a variável resposta está definida no intervalo $(0,1)$ o modelo assume que a cada variável $Y_t$ pode ser escrita da seguinte maneira:

\begin{align}
g(\mu_t)=\alpha+x_t^{T}\beta+\sum_{i=1}^{p}\varphi_i[g(y_{t-i})-x_{t-1}^{T}\beta]+\sum_{j=1}^{q}\theta_{j}r_{t-j}
\end{align}


\subsection{Modelo KARMA}
O modelo KARMA foi introduzido no contexto de séries temporais com o intuito de acomodar a presença de correlação serial na modelagem da mediana condicional da distribuição Kumaraswamy. O modelo KARMA^[Para mais detalhes consultar o artigo] proposto em @bayer2017kumaraswamy assume que a mediana de cada $Y_t$ pode ser escrita da seguinte maneira:

\begin{align}
g(\mu_t)=\alpha+x_t^{T}\beta+\sum_{i=1}^{p}\varphi_i[g(y_{t-i})-x_{t-1}^{T}\beta]+\sum_{j=1}^{q}\theta_{j}r_{t-j}
\end{align}


\section{Análise Descritiva}

```{r, fig.cap="Comportament Médio dos Reviews ao Longo do Tempo"}
plot_serie = df |>
  ggplot(aes(x = Time_submitted, y = rate)) +
  geom_line()

plot_serie

```
```{r}
pvalor = tseries::adf.test(y)$p.value
```



Para a modelagem deve-se verificar se a suposição de estacionariedade  é satisfeita, dessa forma, antes da escolha do modelo realizou-se o teste de raiz unitária de Dickey-Fuller Aumentado (ADF) (Said e Dickey, 1984). Sendo obtido p-valor= 0.06, ao nível de significância de  5%, a hipótese  de não  estacionariedade  é rejeitada. Assumindo que a série estacionária procedeu-se a utilização dos modelos descritos na seguinte seção. 

A Figura fornece a função de autocorrelação e autocorrelação 
```{r}
ggAcf(df$rate) + ggPacf(df$rate) 

```

`
Pode-se notar que por inspeção visual da figura, conclui-se que não existem evidências da série não ser estacionária, assim como visto pelo teste ADF.


```{r}
y |> tibble() |>  fastrep::describe() |> fastrep::tbl("Resumo da Avaliação Média")
```


\section{Ajuste dos Modelos}


Na Tabela 2 são apresentadas as estimativas, o erro padrão e o p-valor associado ao teste de
significância dos parâmetros do modelo $\beta$ARMA(1,1), obtido pelo menor AIC. Verifica-se que os parâmetro são significativos ao nível de significância de 5%
```{r}
fit_barma = barma(y, ar=c(1), ma=c(1), h=15, diag=0)

fit_barma$model |> as.data.frame() |> mutate(`Pr(>|z|)` = format.pval(`Pr(>|z|)`, eps = 0.001)) |>  fastrep::tbl("Resumo do Ajuste BARMA")
```

A Figura 3 apresenta o gráfico da série com os valores reais juntamente com os valores
estimados pelo modelo. O gráfico indica uma boa qualidade do ajuste, já que valores reais
e previstos são muito próximos.

```{r, fig.cap="Valores Reais versus Ajustados pelo Modelo Barma"}

real_hat = function(fitted){
fitted |> tibble() |> rename(y_hat = fitted) |> 
  bind_cols(y = df$rate / 5, data = df$Time_submitted) |> 
  ggplot() +
  geom_line(aes(data, y_hat, color = 'Estimada')) +
  geom_line(aes(data, y, color = 'Real')) + 
  scale_color_manual(name = "Serie", values = c("Estimada" = "red", "Real" = "black"))
}



real_hat(fit_barma$fitted)
```
A tabela fornece as estimativas que foram apresentadas para o modelo $\beta$ARMA, só que agora para o modelo KARMA(1,0).




```{r}
fit_karma = karma(y, ar=c(1), h=15, diag=0)

fit_karma$model |> as.data.frame() |> mutate(`Pr(>|z|)` = format.pval(`Pr(>|z|)`, eps = 0.001)) |>  fastrep::tbl("Resumo do Ajuste KARMA")
```

Podemos pela figura ver que o modelo $KARMA$ visualmente estima bem a série.


```{r}
real_hat(fit_karma$fitted)
```

Porém fica inviável comparar qual tem melhor desempenho somente por gráficos,  dessa maneira assim na seção rr são fornecidas medidas para comparação de modelos.
Dessa maneira para confirmar se o modelo está bem ajustado foi
realizada a análise de diagnóstico na seguinte seção.


\subsection{Análise de Diagnóstico}



Considerando as Figuras, pode-se observar que em apenas uma defasagem o
valor é superior ao intervalo de confiança, dessa forma, aparentemente a suposição de resíduos não correlacionados  é satisfeita, ainda baseado no teste de Ljung-Box, testou-se correlação nula até a defasagem 120, tem-se p-valor=0.3568, logo os resíduos são não correlacionados. A Figura também apresenta os resíduos padronizados ao longo dos indíces, observa-se que apresentam um comportamento aleatório em torno de zero, com os valores dentro dos limites estipulados. Para o gráfico Q-Q plot, verifica-se que a maioria dos pontos se encontra sobre a linha diagonal, indicando a proximidade dos resíduos da distribuição Normal.


```{r, fig.cap="Comportamento dos Resíduos para o Modelo Barma"}
par(mfrow = c(2, 2)) 

res=fit_barma$resid1
resi_padrao=as.vector((res)/(sd(res)))
acf(res)
pacf(res)

n<-length(res)
t<-seq(-5,n+6,by=1)

plot(res, main=" ",xlab="Índices",ylab="Resíduos", pch = "+",ylim=c(-4,4))
lines(t,rep(-3,n+12),lty=2,col=1)
lines(t,rep(3,n+12),lty=2,col=1)
lines(t,rep(-2,n+12),lty=3,col=1)
lines(t,rep(2,n+12),lty=3,col=1)




max_r<- max(res,na.rm=T)
min_r<- min(res,na.rm=T)
qqnorm(resi_padrao, pch = "+",
       xlim=c(0.95*min_r,max_r*1.05),
       ylim=c(0.95*min_r,max_r*1.05),
       main="",xlab="quantis normais",ylab="quantis empiricos")
lines(c(-10,10),c(-10,10),lty=2)
```

Pela Figura, temos os mesmos gráficos porém para o modelo KARMA

```{r, fig.cap="Comportamento dos Resíduos para o Modelo KARMA"}
par(mfrow = c(2, 2)) 

res=fit_karma$resid1
resi_padrao=as.vector((res)/(sd(res)))
acf(res)
pacf(res)

n<-length(res)
t<-seq(-5,n+6,by=1)

plot(res, main=" ",xlab="Índices",ylab="Resíduos", pch = "+",ylim=c(-4,4))
lines(t,rep(-3,n+12),lty=2,col=1)
lines(t,rep(3,n+12),lty=2,col=1)
lines(t,rep(-2,n+12),lty=3,col=1)
lines(t,rep(2,n+12),lty=3,col=1)




max_r<- max(res,na.rm=T)
min_r<- min(res,na.rm=T)
qqnorm(resi_padrao, pch = "+",
       xlim=c(0.95*min_r,max_r*1.05),
       ylim=c(0.95*min_r,max_r*1.05),
       main="",xlab="quantis normais",ylab="quantis empiricos")
lines(c(-10,10),c(-10,10),lty=2)
```



A Figura apresenta os resíduos padronizados ao longo dos indíces, observa-se que apresentam um comportamento aleatório em torno de zero, com os valores dentro dos limites estipulados. A Figura apresenta o gráfico Q-Q plot, verifica-se que a maioria dos pontos se encontra sobre a linha diagonal, indicando a proximidade dos resíduos da distribuição Normal.
```{r}
fit_karma$resid3 |> acf()
```

```{r}
resid_plot = function(model , type = 2){
  type = as.character(type)
  resid = paste("resid", type)
  residuals = eval(parse(text = model$resid))
  residuals
  
}


```
\subsection{Comparação dos Modelos}

Para comparar os modelos vamos utilizar de duas medidas que avaliam a diferença entre os valores reais $y$ e os valores preditos pelo modelo $\hat{\mu}$ , sendo elas o erro quadrático médio (EQM) e o erro percentual absoluto médio (MAPE), sendo definidas:

\begin{align}
\text{EQM} = \dfrac{1}{h}\sum_{i=1}^{h}(y_i - \hat{\mu}_i)^2 \quad \text{MAPE} =  \dfrac{1}{h}\sum_{i=1}^{h}\dfrac{|y_i - \hat{\mu}_i|}{|y_i|}
\end{align}

```{r}
modelo=auto.arima(y, max.p=5, max.q=5, max.P=5, max.Q=5, max.order=5, max.d=2, max.D=1,
                  start.p=1, start.q=1, start.P=1, start.Q=1, stationary=F)
metrics = data.frame(EQM = c(eqm(fit_barma), eqm(fit_karma), eqm(modelo)),
           MAPE = c(mape(fit_barma), mape(fit_karma), mape(modelo)))
row.names(metrics) = c("BARMA", "KARMA", "ARIMA")

metrics |> fastrep::tbl("Medidas nos Período de Ajuste")

```

```{r}

karma_pred = fit_karma$forecast

barma_pred = fit_barma$forecast

test = y[(length(y) - 14):length(y)]



###################### EQM e MAPE período previsao #######################

############### EQM #################
residuos_beta_prev = (test- barma_pred)
#residuos_sarima_prev = (test-as.vector(modelo$))
residuos_arma_prev = (test-as.vector(karma_pred))

eqm_beta_prev = (sum(residuos_beta_prev^2))/length(residuos_beta_prev)
#(eqm_sarima_prev = (sum(residuos_sarima_prev^2))/length(residuos_sarima_prev))
eqm_arma_prev = (sum(residuos_arma_prev^2))/length(residuos_arma_prev)

############### MAPE #################

maple_beta_prev = sum( abs(residuos_beta_prev)/abs(test) )/ length(residuos_beta_prev)
#(maple_sarima_prev = sum( abs(residuos_sarima_prev)/abs(za) )/ length(residuos_sarima_prev))
maple_ar_prev = sum( abs(residuos_arma_prev)/abs(test) )/ length(residuos_arma_prev)


metrics = data.frame(EQM = c(eqm_beta_prev, eqm_arma_prev),
           MAPE = c(maple_beta_prev, maple_ar_prev))
row.names(metrics) = c("BARMA", "KARMA")

metrics |> fastrep::tbl("Medidas nos Período de Previsão")





```



```{r crfgraph, fig.cap = "fig name"}
plot(rnorm(500))
```




\section{Conclusão}

You cross-reference figures like this: Figure \@ref(fig:crfgraph)


# Bibliography



