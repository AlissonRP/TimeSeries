---
title: "As Avaliações do Spotify Ao Longo do Tempo"
author: "Alisson Rosa"
abstract: "abstract"
header-includes:
   - \usepackage[brazil]{babel}
   - \usepackage{bm}
   - \usepackage{float}
geometry: left=1.7cm, right=1.7cm, top=3cm, bottom=3cm
output:
  bookdown::pdf_document2:
    includes:
      before_body: beforebody.tex
editor_options:
  chunk_output_type: console
indent: true
toc: True
bibliography: bib.bib 
csl: style.csl
nocite: '@*'
link-citations: true
---




```{r setup,include=F}

options(digits = 4) # Arrendodamento
options(scipen = 999)
ggplot2::theme_set(ggplot2::theme_minimal())
knitr::opts_chunk$set(
  echo = F, message = F, warning = F, fig.pos = "H",
  fig.align = "center", fig.width = 6, fig.height = 3.5
)
scale_fill_discrete <- \(...) ggplot2::scale_fill_brewer(..., palette = "Set2")
```


\section{Introdução}
O Spotify é um serviço digital que dá acesso instantâneo a milhões de músicas, podcasts, vídeos e outros conteúdos de criadores no mundo todo. Pode ser acessado pelo *browser*, sendo possível também baixar o aplicativo, estando disponível para diversas plataformas digitais. 
Nesse ensaio, vamos analisar os *reviews* feitos na Play Store sobre a versão para *Android*, dessa maneira vamos examinar o comportamento da média dos reviews (estrelas) diária em uma perspectiva de série temporal, uma outra abordagem utilizando técnicas de NLP pode ser consultada clicando-se [aqui](https://github.com/AlissonRP/SpotifyReviews/blob/main/report.pdf).

```{r }
# R code
library(tidyverse)
library(forecast)
library(lubridate)
library(patchwork)




eqm = function(model, serie = y, ar=2){
  ar = ar + 1
  resid = serie[ar:length(serie)] - model$fitted[ar:length(serie)]
  return(sum(resid^2) / (length(resid) - 1))
  
}

mape = function(model,  serie = y, ar = 2){
  ar = ar + 1
  resid = serie[ar:length(serie)] - model$fitted[ar:length(serie)]
  return((1/length(serie)) * sum(abs(resid)/abs(y[2:length(y)])))
}

source("analise_barmax/barma.r")
source("KARMA_BARMA/karma.r")

df = read_csv("../data/rates.csv")

df = df |>
  mutate(Time_submitted  = as.Date(Time_submitted, format = "%Y-%m-%d"))


df = df |> group_by(
  Time_submitted) |>
  summarise(rate = mean(Rating))

df = df[1:(nrow(df)-4), ]

df = df |>  bind_cols(index = 1:nrow(df))
y = df$rate /  5
y <- ts(y, start = decimal_date(as.Date("2022-01-01")), frequency = 365)
```





\section{Análise Descritiva}
Devemos iniciar avaliando o comportamento da série ao longo do tempo, para averiguar a existência de evidências de não estacionariedade ou sazonalidade, tal fato pode ser visto pela Figura \@ref(fig:serie).

```{r serie, fig.cap="Comportament Médio dos Reviews ao Longo do Tempo"}
plot_serie = df |>
  ggplot(aes(x = Time_submitted, y = rate)) +
  geom_line()

plot_serie

```
```{r}
pvalor = tseries::adf.test(y)$p.value
```

Nota-se que a série tem alguns picos de avaliações médias baixas, porém tende a variar em torno de uma média, pode ser visto também a não existência de sazonalidade. Além da análise visual faz-se necessário a utilização de teste de hipóteses para averiguar os fatos constatados anteriormente, dessa forma, antes da escolha do modelo realizou-se o teste de raiz unitária de Dickey-Fuller Aumentado (ADF). Sendo obtido um de p-valor= 0.05, ao nível de significância de  5%, a hipótese  de não  estacionariedade  é rejeitada. Assumindo que a série estacionária procedeu-se a utilização dos modelos descritos na seguinte seção. 

A Figura \@ref(fig:pacf) fornece a função de autocorrelação e autocorrelação parcial, Pode-se notar por inspeção visual da figura, que não existem evidências da série não ser estacionária, assim como visto pelo teste ADF e pela \@ref(fig:serie).
```{r pacf}
ggAcf(df$rate) + labs(title="Review Médio") + ggPacf(df$rate) + labs(title="Review Médio")

```




```{r}
y |> tibble() |>  fastrep::describe() |> fastrep::tbl("Resumo da Avaliação Média")
```



\section{Metodologia}
Nessa seção são apresentados os modelos aqui utilizados, a saber: $\beta$ARMA, KARMA e ARIMA^[ARIMA: O modelo ARIMA já é bastante conhecido na literatura, portanto aqui é dispensado a sua introdução]

\subsection{Modelo $\beta$ARMA}
A distribuição beta é bastante conhecida pois consegue modelar variáveis aleatórias definidas em intervalos limitados, dessa maneira um caso particular importante é quando o intervalo é unitário iniciando em zero. Dessa maneira, foi desenvolvido em @betarma o modelo com abordagem temporal para variáveis que podem ser modeladas pela distribuição beta.

Portanto, assumindo que a variável resposta está definida no intervalo $(0,1)$ o modelo assume que a cada variável $Y_t$ pode ser escrita da seguinte maneira:

\begin{align}
g(\mu_t)=\alpha+x_t^{T}\beta+\sum_{i=1}^{p}\varphi_i[g(y_{t-i})-x_{t-1}^{T}\beta]+\sum_{j=1}^{q}\theta_{j}r_{t-j}
\end{align}


\subsection{Modelo KARMA}
O modelo KARMA foi introduzido no contexto de séries temporais com o intuito de acomodar a presença de correlação serial na modelagem da mediana condicional da distribuição Kumaraswamy. O modelo KARMA^[Para mais detalhes consultar o artigo] proposto em @bayer2017kumaraswamy assume que a mediana de cada $Y_t$ pode ser escrita da seguinte maneira:

\begin{align}
g(\mu_t)=\alpha+x_t^{T}\beta+\sum_{i=1}^{p}\varphi_i[g(y_{t-i})-x_{t-1}^{T}\beta]+\sum_{j=1}^{q}\theta_{j}r_{t-j}
\end{align}





\section{Ajuste dos Modelos}


Na Tabela 2 são apresentadas as estimativas, o erro padrão e o p-valor associado ao teste de
significância dos parâmetros do modelo $\beta$ARMA(4,3), obtido pelo menor AIC. Verifica-se que os parâmetro são significativos ao nível de significância de 5%
```{r}
fit_barma = barma(y, ar=c(1,3,4,5), ma=c(1,2,3), h=13, diag=0)

fit_barma$model |> as.data.frame() |> mutate(`Pr(>|z|)` = format.pval(`Pr(>|z|)`, eps = 0.001)) |>  fastrep::tbl("Resumo do Ajuste BARMA")
```

A Figura 3 apresenta o gráfico da série com os valores reais juntamente com os valores
estimados pelo modelo. O gráfico indica uma boa qualidade do ajuste, já que valores reais
e previstos são muito próximos.

```{r, fig.cap="Valores Reais versus Ajustados pelo Modelo Barma"}

real_hat = function(fitted){
fitted |> tibble() |> rename(y_hat = fitted) |> 
  bind_cols(y = df$rate / 5, data = df$Time_submitted) |> 
  ggplot() +
  geom_line(aes(data, y_hat, color = 'Estimada')) +
  geom_line(aes(data, y, color = 'Real')) + 
  scale_color_manual(name = "Serie", values = c("Estimada" = "red", "Real" = "black"))
}



real_hat(fit_barma$fitted)
```
A tabela fornece as estimativas que foram apresentadas para o modelo $\beta$ARMA, só que agora para o modelo KARMA(1,0).




```{r}
fit_karma = karma(y, ar=c(1), h=13, diag=0)

fit_karma$model |> as.data.frame() |> mutate(`Pr(>|z|)` = format.pval(`Pr(>|z|)`, eps = 0.001)) |>  fastrep::tbl("Resumo do Ajuste KARMA")
```

Podemos pela figura ver que o modelo $KARMA$ visualmente estima bem a série.


```{r}
real_hat(fit_karma$fitted)
```

Porém fica inviável comparar qual tem melhor desempenho somente por gráficos,  dessa maneira assim na seção rr são fornecidas medidas para comparação de modelos.
Dessa maneira para confirmar se o modelo está bem ajustado foi
realizada a análise de diagnóstico na seguinte seção.


\subsection{Análise de Diagnóstico}



Considerando as Figura \@ref(fig:residuals) que fornece os gráficos para diagnóstico do modelo $\beta$ARMA, pode-se observar que em apenas uma defasagem o
valor é superior ao intervalo de confiança, dessa forma, aparentemente a suposição de resíduos não correlacionados  é satisfeita, ainda baseado no teste de Ljung-Box, testou-se correlação nula até a defasagem 20, tem-se p-valor=0.3568, logo os resíduos são não correlacionados. A Figura também apresenta os resíduos padronizados ao longo dos indíces, observa-se que apresentam um comportamento aleatório em torno de zero, com os valores dentro dos limites estipulados. Para o gráfico Q-Q plot, verifica-se que a maioria dos pontos se encontra sobre a linha diagonal, indicando a proximidade dos resíduos da distribuição Normal.


```{r residuals, fig.cap="Comportamento dos Resíduos para o Modelo Barma", fig.height = 4.7}
par(mfrow = c(2, 2)) 

res=fit_barma$resid1
resi_padrao=as.vector((res)/(sd(res)))
acf(res, cex.lab=0.8, cex.main=0.3, cex.axis=0.7, main="")
pacf(res, cex.lab=0.8, cex.main=0.3, cex.axis=0.7, main="")

n<-length(res)
t<-seq(-5,n+6,by=1)

plot(res, main=" ",xlab="Índices",ylab="Resíduos", pch = "+",ylim=c(-4,4), cex.lab=0.8, cex.main=0.3, cex.axis=0.7)
lines(t,rep(-3,n+12),lty=2,col=1)
lines(t,rep(3,n+12),lty=2,col=1)
lines(t,rep(-2,n+12),lty=3,col=1)
lines(t,rep(2,n+12),lty=3,col=1)




max_r<- max(res,na.rm=T)
min_r<- min(res,na.rm=T)
qqnorm(resi_padrao, pch = "+",
       xlim=c(0.95*min_r,max_r*1.05),
       ylim=c(0.95*min_r,max_r*1.05),
       main="",xlab="quantis normais",ylab="quantis empiricos", cex.lab=0.8, cex.main=0.3, cex.axis=0.7)
lines(c(-10,10),c(-10,10),lty=2)
```

Pela Figura \@ref(fig:resikarma), temos os mesmos gráficos porém para o modelo KARMA, nesse caso nenhum dos pressupostos é satisfeitos, dado que temos inúmeras autocorrelações superiores aos intervalos de confiança, indicando autocorrelação nos resíduos. Os resíduos versus índices indica um padrão e também os resíduos estão bastantes "distantes" da distribuição normal.

```{r resikarma, fig.cap="Comportamento dos Resíduos para o Modelo KARMA", fig.height = 4.7}
par(mfrow = c(2, 2)) 

res=fit_karma$resid1
resi_padrao=as.vector((res)/(sd(res)))
acf(res, cex.lab=0.8, cex.main=0.3, cex.axis=0.7, main="")
pacf(res, cex.lab=0.8, cex.main=0.3, cex.axis=0.7, main="")

n<-length(res)
t<-seq(-5,n+6,by=1)

plot(res, main=" ",xlab="Índices",ylab="Resíduos", pch = "+",ylim=c(-4,4), cex.lab=0.8, cex.main=0.3, cex.axis=0.7)
lines(t,rep(-3,n+12),lty=2,col=1)
lines(t,rep(3,n+12),lty=2,col=1)
lines(t,rep(-2,n+12),lty=3,col=1)
lines(t,rep(2,n+12),lty=3,col=1)




max_r<- max(res,na.rm=T)
min_r<- min(res,na.rm=T)
qqnorm(resi_padrao, pch = "+",
       xlim=c(0.95*min_r,max_r*1.05),
       ylim=c(0.95*min_r,max_r*1.05),
       main="", xlab="quantis normais", ylab="quantis empiricos", cex.lab=0.8, cex.main=0.3, cex.axis=0.7)
lines(c(-10,10),c(-10,10),lty=2)
```



A Figura apresenta os resíduos padronizados ao longo dos indíces, observa-se que apresentam um comportamento aleatório em torno de zero, com os valores dentro dos limites estipulados. A Figura apresenta o gráfico Q-Q plot, verifica-se que a maioria dos pontos se encontra sobre a linha diagonal, indicando a proximidade dos resíduos da distribuição Normal.



\subsection{Comparação dos Modelos}

Para comparar os modelos vamos utilizar de duas medidas que avaliam a diferença entre os valores reais $y$ e os valores preditos pelo modelo $\hat{\mu}$ , sendo elas o erro quadrático médio (EQM) e o erro percentual absoluto médio (MAPE), sendo definidas:

\begin{align}
\text{EQM} = \dfrac{1}{h}\sum_{i=1}^{h}(y_i - \hat{\mu}_i)^2 \quad; \text{MAPE} =  \dfrac{1}{h}\sum_{i=1}^{h}\dfrac{|y_i - \hat{\mu}_i|}{|y_i|}
\end{align}
Pela tabela \@ref(tab:train) notamos o que era esperado pela análise de diagnóstico, o modelo KARMA tende a ter um desempenho inferior aos demais, e por uma leve diferença o modelo $\beta$ARMA tende a ser o melhor nos dados de treino/ajuste.

```{r train}
modelo=auto.arima(y, max.p=5, max.q=5, max.P=5, max.Q=5, max.order=5, max.d=2, max.D=1,
                  start.p=1, start.q=1, start.P=1, start.Q=1, stationary=F)
metrics = data.frame(EQM = c(eqm(fit_barma, ar = 5), eqm(fit_karma), eqm(modelo)),
           MAPE = c(mape(fit_barma, ar = 5), mape(fit_karma), mape(modelo)))
row.names(metrics) = c("BARMA", "KARMA", "ARIMA")

metrics |> fastrep::tbl("Medidas nos Período de Ajuste")


```
Entretanto os resultados são diferente para o caso dos dados de teste/previsão.
    pois o que se nota pela Tabela \@ref(tab:test) é que o modelo $\beta$ARMA tende a ter um desempenho inferior em ambas as métricas. Uma situação que evidência que alinhamento de pressupostos nem sempre acarreta em melhores previsões.
```{r test}

karma_pred = fit_karma$forecast

barma_pred = fit_barma$forecast


test = y[(length(y) - 12):length(y)]




###################### EQM e MAPE período previsao #######################

############### EQM #################
residuos_beta_prev = (test- barma_pred)
#residuos_sarima_prev = (test-as.vector(modelo$))
residuos_arma_prev = (test-as.vector(karma_pred))

eqm_beta_prev = (sum(residuos_beta_prev^2))/length(residuos_beta_prev)
#(eqm_sarima_prev = (sum(residuos_sarima_prev^2))/length(residuos_sarima_prev))
eqm_arma_prev = (sum(residuos_arma_prev^2))/length(residuos_arma_prev)

############### MAPE #################

maple_beta_prev = sum( abs(residuos_beta_prev)/abs(test) )/ length(residuos_beta_prev)
#(maple_sarima_prev = sum( abs(residuos_sarima_prev)/abs(za) )/ length(residuos_sarima_prev))
maple_ar_prev = sum( abs(residuos_arma_prev)/abs(test) )/ length(residuos_arma_prev)


metrics = data.frame(EQM = c(eqm_beta_prev, eqm_arma_prev),
           MAPE = c(maple_beta_prev, maple_ar_prev))
row.names(metrics) = c("BARMA", "KARMA")

metrics |> fastrep::tbl("Medidas nos Período de Previsão")





```


```{r, fig.height = 4.5, fig.width = 6.9, fig.cap="Dados Reais e Ajustados pelo Modelo"}


plot(test, col=1, type="l", axes = T, main="", xlab="Indíce", ylab="Review Média")
lines((barma_pred), lty = 1, lwd = 1, col=2)
lines((karma_pred), lty = 2, lwd = 2, col=2)
legend("topright",c("Valores reais","Valores ajustados - BARMA","Valores ajustados - KARMA"),#pch=vpch,
       pt.bg="white", lty=c(1,1),  col=c(1,2), bty="n")
axis(1)
axis(2)


```




\section{Conclusão}

Contemplamos o comportamento dos reviews médio diário do Spotify na *Play Store*, nota-se que não existem evidências de não estacionaridade e nem para a existência de sazonalidade. Para os modelos ajustados, o modelo KARMA não teve um desempenho agradável para os pressupostos, dado o comportamento dos resíduos, o modelo $\beta$ARMA foi o que obteve destaque, tanto em termos de pressupostos quanto em perfomance nos dados de treino, entretanto para os dados de teste sofreu a perda em termos da métrica para o KARMA.




# Bibliografia



